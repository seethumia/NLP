{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seethu-8363/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis:\n",
    "    def data_preproc(self):\n",
    "        \n",
    "        #Loading the data\n",
    "        data = open('/Users/seethu-8363/Downloads/amazon_reviews.csv').read()\n",
    "        \n",
    "        labels, texts = [], []\n",
    "        for i, line in enumerate(data.split(\"\\n\")):\n",
    "            content = line.split()\n",
    "            labels.append(content[0])\n",
    "            texts.append(\" \".join(content[1:]))\n",
    "        # create a dataframe using texts and lables\n",
    "        trainDF = pd.DataFrame()\n",
    "        trainDF['text'] = texts\n",
    "        trainDF['label'] = labels\n",
    "        \n",
    "        #lower case\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        trainDF[\"text\"].head()\n",
    "        \n",
    "        #STOP WORDS\n",
    "        #Removal of stop words\n",
    "        stop = stopwords.words('english')\n",
    "        ##Creating a list of custom stopwords\n",
    "        new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\",\"way\",\"ever\",\n",
    "             \"us\",\"up\",\"cd\",\"that\",\"all\",\"second\"]\n",
    "        stop.append(new_words)\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "        \n",
    "        \n",
    "        #Removal of punctautaion \n",
    "        trainDF[\"text\"] = trainDF[\"text\"].str.replace('[^\\w\\s]','  ')\n",
    "\n",
    "        \n",
    "        # split the dataset into training and validation datasets \n",
    "        train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'],test_size = 0.8)\n",
    "        \n",
    "        # label encode the target variable \n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        train_y = encoder.fit_transform(train_y)\n",
    "        valid_y = encoder.fit_transform(valid_y)\n",
    "        \n",
    "    \n",
    "        return train_x, train_y, valid_x, valid_y\n",
    "        \n",
    "    def train_model_pipeline(self, classifier, train_x, label , valid_x , valid_y):\n",
    "            # fit the training dataset on the classifier\n",
    "            \n",
    "            tfidf_vectorizer = TfidfVectorizer()\n",
    "            nb = classifier\n",
    "            #creating pipeline for model mand vectoriser\n",
    "            tfidf_nv_pipe = Pipeline([('tfidf', tfidf_vectorizer), ('nb', nb)])\n",
    "\n",
    "            #Fitting the data\n",
    "            tfidf_nv_pipe.fit(train_x,label)\n",
    "    \n",
    "            # predict the labels on validation dataset\n",
    "            predictions = tfidf_nv_pipe.predict(valid_x)\n",
    "    \n",
    "            return metrics.f1_score(predictions, valid_y) , tfidf_nv_pipe\n",
    "    \n",
    "    def load_model(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Naive Bayes Bernoulli on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(naive_bayes.BernoulliNB(), train_x, train_y, valid_x , valid_y)\n",
    "     \n",
    "        #pickle model\n",
    "        joblib.dump(model,current_path+\"/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "        print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "        \n",
    "        return model,accuracy\n",
    "    \n",
    "    def load_model1(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Naive Bayes Multinomial on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(naive_bayes.MultinomialNB(), train_x.toarray(), train_y.toarray(), valid_x.toarray() , valid_y.toarray())\n",
    "     \n",
    "        #pickle model\n",
    "        joblib.dump(model,current_path+\"/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "        print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "        \n",
    "        return model,accuracy\n",
    "    \n",
    "    def load_model2(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Naive Bayes Gaussian on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(naive_bayes.GaussianNB(), train_x, train_y, valid_x , valid_y)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def load_model3(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Linear SVM on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(svm.LinearSVC(), train_x, train_y, valid_x , valid_y)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def load_model4(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Linear SVM on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(svm.LinearSVC(), train_x, train_y, valid_x , valid_y)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def prediction(self,input_str):\n",
    "            train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "            model,accuracy = self.load_model(train_x , train_y , valid_x , valid_y)\n",
    "            print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "            \n",
    "            predictions = model.predict([input_str])\n",
    "            \n",
    "            print(\"prediction:\",predictions)\n",
    "            #loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "\n",
    "    def prediction1(self,input_str):\n",
    "            train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "            accuracy = self.load_model1(train_x , train_y , valid_x , valid_y)\n",
    "            print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "            #loaded_modl = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "\n",
    "            \n",
    "    def prediction2(self,input_str):\n",
    "            train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "            accuracy = self.load_model2(train_x , train_y , valid_x , valid_y)\n",
    "            print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "            #loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    def prediction2(self,input_str):\n",
    "            train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "            accuracy = self.load_model2(train_x , train_y , valid_x , valid_y)\n",
    "            print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "            #loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "\n",
    "        \n",
    "    def prediction3(self,input_str):\n",
    "            train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "            accuracy = self.load_model3(train_x , train_y , valid_x , valid_y)\n",
    "            print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "            #loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF ACCURACY:  0.7881413293623933\n",
      "NB, WordLevel TF-IDF ACCURACY:  0.7881413293623933\n",
      "prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli\n",
    "obj = sentiment_analysis()\n",
    "obj.prediction('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF ACCURACY:  0.7868162692847125\n",
      "NB, WordLevel TF-IDF ACCURACY:  (Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('nb',\n",
      "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
      "         verbose=False), 0.7868162692847125)\n"
     ]
    }
   ],
   "source": [
    "#Multinomail\n",
    "obj = naive_bayes_sentiment()\n",
    "obj.prediction1('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b5b18821692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Gaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'good'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-bda158cb7d46>\u001b[0m in \u001b[0;36mprediction2\u001b[0;34m(self, input_str)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprediction2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mtrain_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NB, WordLevel TF-IDF ACCURACY: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m#loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/sentiment_analysis_naive_bayes_model.pkl\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-bda158cb7d46>\u001b[0m in \u001b[0;36mload_model2\u001b[0;34m(self, train_x, train_y, valid_x, valid_y)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Naive Bayes on Word Level TF IDF Vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-bda158cb7d46>\u001b[0m in \u001b[0;36mtrain_model_pipeline\u001b[0;34m(self, classifier, train_x, label, valid_x, valid_y)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#Fitting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtfidf_nv_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# predict the labels on validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    191\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    484\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Test/virenv1/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    289\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "#Gaussian\n",
    "obj = naive_bayes_sentiment()\n",
    "obj.prediction2('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF ACCURACY:  0.8190211205261161\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "obj = naive_bayes_sentiment()\n",
    "obj.prediction3('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
