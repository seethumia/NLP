{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import joblib \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chit_chat:\n",
    "    \n",
    "    def data_preproc(self):\n",
    "        \n",
    "        #Loading the data\n",
    "        data = open('chit_chat.txt').read()\n",
    "        \n",
    "        labels, texts = [], []\n",
    "        for i, line in enumerate(data.split(\"\\n\")):\n",
    "            content = line.split()\n",
    "            labels.append(content[0])\n",
    "            texts.append(\" \".join(content[1:]))\n",
    "        # create a dataframe using texts and lables\n",
    "        trainDF = pd.DataFrame()\n",
    "        trainDF['text'] = texts\n",
    "        trainDF['label'] = labels\n",
    "        \n",
    "        #lower case\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        trainDF[\"text\"].head()\n",
    "        \n",
    "        #STOP WORDS\n",
    "        #Removal of stop words\n",
    "        stop = stopwords.words('english')\n",
    "        ##Creating a list of custom stopwords\n",
    "        new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\",\"way\",\"ever\",\n",
    "             \"us\",\"up\",\"cd\",\"that\",\"all\",\"second\"]\n",
    "        stop.append(new_words)\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "        \n",
    "        \n",
    "        #Removal of punctautaion \n",
    "        trainDF[\"text\"] = trainDF[\"text\"].str.replace('[^\\w\\s]','  ')\n",
    "        \n",
    "        \n",
    "#         #Lemmatization\n",
    "#         lemmatizer = WordNetLemmatizer()\n",
    "#         trainDF['text'] = lemmatizer.lemmatize(trainDF[\"text\"])\n",
    "    \n",
    "        \n",
    "        # split the dataset into training and validation datasets \n",
    "        train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'],test_size = 0.6, random_state = 42)\n",
    "        \n",
    "        # label encode the target variable \n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        train_y = encoder.fit_transform(train_y)\n",
    "        valid_y = encoder.fit_transform(valid_y)\n",
    "        \n",
    "    \n",
    "        return train_x, train_y, valid_x, valid_y\n",
    "        \n",
    "    def train_model_pipeline(self, classifier, train_x, label , valid_x , valid_y):\n",
    "            # fit the training dataset on the classifier\n",
    "            \n",
    "            tfidf_vectorizer = TfidfVectorizer()\n",
    "            nb = classifier\n",
    "            #creating pipeline for model mand vectoriser\n",
    "            tfidf_nv_pipe = Pipeline([('tfidf', tfidf_vectorizer), ('nb', nb)])\n",
    "\n",
    "            #Fitting the data\n",
    "            tfidf_nv_pipe.fit(train_x,label)\n",
    "    \n",
    "            # predict the labels on validation dataset\n",
    "            predictions = tfidf_nv_pipe.predict(valid_x)\n",
    "    \n",
    "            return metrics.f1_score(predictions,valid_y,average = 'micro') , tfidf_nv_pipe\n",
    "    \n",
    "\n",
    "    def load_model(self, train_x , train_y , valid_x , valid_y):\n",
    "        \n",
    "        # Naive Bayes Multinomial on Word Level TF IDF Vectors\n",
    "        accuracy,model = self.train_model_pipeline(naive_bayes.MultinomialNB(), train_x, train_y, valid_x , valid_y)\n",
    "     \n",
    "        #pickle model\n",
    "        joblib.dump(model,current_path+\"/model/chat_bot_firstCut.pkl\")\n",
    "        print(\"NB, WordLevel TF-IDF ACCURACY: \", accuracy)\n",
    "        \n",
    "        return model,accuracy\n",
    "    \n",
    "    def predictions(self,inp_str):\n",
    "            try:\n",
    "                loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/chat_bot_firstCut.pkl\")\n",
    "                res = loaded_model.predict([inp_str])\n",
    "            except:\n",
    "                train_x , train_y , valid_x , valid_y = self.data_preproc()\n",
    "                model = self.load_model(train_x , train_y , valid_x , valid_y)\n",
    "                loaded_model = joblib.load(\"/Users/seethu-8363/Documents/Test/virenv1/model/chat_bot_firstCut.pkl\")\n",
    "                res = loaded_model.predict([inp_str])\n",
    "            \n",
    "            \n",
    "            if res == 0 : \n",
    "                return \"Howdy partner,Hope you are having a fun day...How may i assist u?\"\n",
    "            \n",
    "            elif res == 1 :\n",
    "                a = ['fun','funny','joke','joking']\n",
    "                if any(x in inp_str for x in a):\n",
    "                    return \"jokes\"\n",
    "                elif \"hi\" in inp_str:\n",
    "                    return \"wassuppp\"\n",
    "                else:\n",
    "                    return \"sorry u lost me\"    \n",
    "               \n",
    "            elif res == 2 :\n",
    "                return \"some song\"\n",
    "            \n",
    "            elif res == 3 :\n",
    "                return \"fun facts\"\n",
    "           \n",
    "            elif res == 4 :\n",
    "                return \"Now now that's personel isn't it\"\n",
    "            \n",
    "            elif res == 5 :\n",
    "                return \"Perhaps a song could cheer u up....\"\n",
    "            \n",
    "            elif res == 6 : \n",
    "                 return \"I could sing,crack a joke or two.Not to brag but care for some fun facts.I'm ur guy bro\"\n",
    "            \n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perhaps a song could cheer u up....'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multinomial NB\n",
    "obj = chit_chat()\n",
    "obj.predictions(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_str = \"hii!!!\"\n",
    "any(trainDF[trainDF.text.apply(lambda x : inp_str in x)])  \n",
    "\n",
    "\n",
    "if \"hi\" in inp_str:\n",
    "    print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "# lemmatizer = WordNetLemmatizer() \n",
    "# print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "# print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"developing\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        #Loading the data\n",
    "        data = open('chit_chat.txt').read()\n",
    "        \n",
    "        labels, texts = [], []\n",
    "        for i, line in enumerate(data.split(\"\\n\")):\n",
    "            content = line.split()\n",
    "            labels.append(content[0])\n",
    "            texts.append(\" \".join(content[1:]))\n",
    "        # create a dataframe using texts and lables\n",
    "        trainDF = pd.DataFrame()\n",
    "        trainDF['text'] = texts\n",
    "        trainDF['label'] = labels\n",
    "        \n",
    "        #lower case\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        trainDF[\"text\"].head()\n",
    "        \n",
    "        #STOP WORDS\n",
    "        #Removal of stop words\n",
    "        stop = stopwords.words('english')\n",
    "        ##Creating a list of custom stopwords\n",
    "        new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\",\"way\",\"ever\",\n",
    "             \"us\",\"up\",\"cd\",\"that\",\"all\",\"second\"]\n",
    "        stop.append(new_words)\n",
    "        trainDF[\"text\"] = trainDF[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "        \n",
    "        \n",
    "        #Removal of punctautaion \n",
    "        trainDF[\"text\"] = trainDF[\"text\"].str.replace('[^\\w\\s]','  ')\n",
    "        \n",
    "        \n",
    "#         #Lemmatization\n",
    "#         lemmatizer = WordNetLemmatizer()\n",
    "#         trainDF['text'] = lemmatizer.lemmatize(trainDF[\"text\"])\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>i  m bored   sing song</td>\n",
       "      <td>label_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>i  m bored</td>\n",
       "      <td>label_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>i  m dieing boredom</td>\n",
       "      <td>label_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>im bored death</td>\n",
       "      <td>label_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>bored death</td>\n",
       "      <td>label_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text    label\n",
       "90   i  m bored   sing song  label_2\n",
       "173              i  m bored  label_5\n",
       "174     i  m dieing boredom  label_5\n",
       "185          im bored death  label_5\n",
       "193             bored death  label_5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF[trainDF.text.apply(lambda x : \"bored\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"chit_chat.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainDF[trainDF.label.apply(lambda x : \"label_1\" in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
